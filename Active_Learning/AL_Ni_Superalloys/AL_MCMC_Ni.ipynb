{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from scipy.stats import pearsonr\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "from pyro.infer import Predictive\n",
    "from pyro.infer import MCMC, NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ni</th>\n",
       "      <th>Al</th>\n",
       "      <th>Co</th>\n",
       "      <th>Cr</th>\n",
       "      <th>Mo</th>\n",
       "      <th>Re</th>\n",
       "      <th>Ru</th>\n",
       "      <th>Ta</th>\n",
       "      <th>W</th>\n",
       "      <th>Ti</th>\n",
       "      <th>Nb</th>\n",
       "      <th>T</th>\n",
       "      <th>log_stress</th>\n",
       "      <th>log_creep_life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.80</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>950</td>\n",
       "      <td>2.267172</td>\n",
       "      <td>3.276554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.30</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>2.136721</td>\n",
       "      <td>3.026370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.80</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2.389166</td>\n",
       "      <td>3.009026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.30</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2.389166</td>\n",
       "      <td>2.969556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.68</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>2.079181</td>\n",
       "      <td>2.957607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>61.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1100</td>\n",
       "      <td>2.322219</td>\n",
       "      <td>1.155336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>61.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1070</td>\n",
       "      <td>2.447158</td>\n",
       "      <td>1.089905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>61.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1100</td>\n",
       "      <td>2.352183</td>\n",
       "      <td>0.991226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>61.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1100</td>\n",
       "      <td>2.342423</td>\n",
       "      <td>0.968483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>61.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1070</td>\n",
       "      <td>2.434569</td>\n",
       "      <td>0.919078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ni   Al   Co   Cr   Mo   Re   Ru   Ta    W   Ti   Nb     T  \\\n",
       "0    62.80  5.6  9.0  6.5  0.6  3.0  0.0  6.5  6.0  0.0  0.0   950   \n",
       "1    59.30  5.8  5.8  2.9  3.9  4.9  6.0  5.6  5.8  0.0  0.0  1100   \n",
       "2    59.80  5.6  5.6  4.6  2.4  6.4  5.0  5.6  5.0  0.0  0.0  1000   \n",
       "3    59.30  5.8  5.8  2.9  3.9  4.9  6.0  5.6  5.8  0.0  0.0  1000   \n",
       "4    61.68  6.0  9.0  3.5  1.5  4.0  0.0  8.0  6.0  0.2  0.0  1100   \n",
       "..     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "148  61.00  5.6  9.0  4.3  2.0  2.0  0.0  7.5  8.0  0.0  0.5  1100   \n",
       "149  61.00  5.6  9.0  4.3  2.0  2.0  0.0  7.5  8.0  0.0  0.5  1070   \n",
       "150  61.00  5.6  9.0  4.3  2.0  2.0  0.0  7.5  8.0  0.0  0.5  1100   \n",
       "151  61.00  5.6  9.0  4.3  2.0  2.0  0.0  7.5  8.0  0.0  0.5  1100   \n",
       "152  61.00  5.6  9.0  4.3  2.0  2.0  0.0  7.5  8.0  0.0  0.5  1070   \n",
       "\n",
       "     log_stress  log_creep_life  \n",
       "0      2.267172        3.276554  \n",
       "1      2.136721        3.026370  \n",
       "2      2.389166        3.009026  \n",
       "3      2.389166        2.969556  \n",
       "4      2.079181        2.957607  \n",
       "..          ...             ...  \n",
       "148    2.322219        1.155336  \n",
       "149    2.447158        1.089905  \n",
       "150    2.352183        0.991226  \n",
       "151    2.342423        0.968483  \n",
       "152    2.434569        0.919078  \n",
       "\n",
       "[153 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creep_df = pd.read_csv('Ni_superalloys_dataset.csv')\n",
    "creep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN(PyroModule):\n",
    "    def __init__(self, in_dim=13, out_dim=1, hid_dim=10, n_hid_layers=5, prior_scale=5.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = nn.Tanh()  # could also be ReLU or LeakyReLU\n",
    "        assert in_dim > 0 and out_dim > 0 and hid_dim > 0 and n_hid_layers > 0  # make sure the dimensions are valid\n",
    "\n",
    "        # Define the layer sizes and the PyroModule layer list\n",
    "        self.layer_sizes = [in_dim] + n_hid_layers * [hid_dim] + [out_dim]\n",
    "        layer_list = [PyroModule[nn.Linear](self.layer_sizes[idx - 1], self.layer_sizes[idx]) for idx in\n",
    "                      range(1, len(self.layer_sizes))]\n",
    "        self.layers = PyroModule[torch.nn.ModuleList](layer_list)\n",
    "\n",
    "        for layer_idx, layer in enumerate(self.layers):\n",
    "            layer.weight = PyroSample(dist.Normal(0., prior_scale * np.sqrt(2 / self.layer_sizes[layer_idx])).expand(\n",
    "                [self.layer_sizes[layer_idx + 1], self.layer_sizes[layer_idx]]).to_event(2))\n",
    "            layer.bias = PyroSample(dist.Normal(0., prior_scale).expand([self.layer_sizes[layer_idx + 1]]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        # x = x.reshape(-1, 1)\n",
    "        x = self.activation(self.layers[0](x))  # input --> hidden\n",
    "        for layer in self.layers[1:-1]:\n",
    "            x = self.activation(layer(x))  # hidden --> hidden\n",
    "        mu = self.layers[-1](x).squeeze()  # hidden --> output\n",
    "        sigma = pyro.sample(\"sigma\", dist.Gamma(.5, 1))  # infer the response noise\n",
    "\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mu, sigma * sigma), obs=y)\n",
    "        return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_state = 123\n",
    "test_size = 0.2\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(np.array(creep_df.iloc[:, 0:13]), np.array(creep_df.iloc[:,13]), shuffle=True, test_size=test_size, random_state=rm_state)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(y))\n",
    "\n",
    "train_ratio = 0.1\n",
    "X_train, _, y_train, _, idx_train, idx_pool = train_test_split(X, y, idx, train_size=train_ratio, shuffle=True, random_state=rm_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcc_variance = []\n",
    "r2_variance = []\n",
    "rmse_variance = []\n",
    "mae_variance = []\n",
    "num_training_data=[]\n",
    "\n",
    "\n",
    "pcc_random = []\n",
    "r2_random = []\n",
    "num_iteration = []\n",
    "\n",
    "X_train_var = X_train\n",
    "X_train_ran = X_train\n",
    "y_train_var = y_train\n",
    "y_train_ran = y_train\n",
    "idx_pool_var = idx_pool\n",
    "idx_pool_ran = idx_pool\n",
    "idx_train_var = idx_train\n",
    "idx_train_ran = idx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing iteration : 0\n",
      "Number of training data with variance: 12\n",
      "Number of pooling data with variance: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [01:05,  3.04it/s, step size=2.10e-02, acc. prob=0.928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.15087347084500985\n",
      "R2_test variance -0.6523343664829939\n",
      "RMSE 0.449117333535391\n",
      "MAE 0.320401441339328\n",
      "Performing iteration : 1\n",
      "Number of training data with variance: 20\n",
      "Number of pooling data with variance: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [03:38,  1.09s/it, step size=3.98e-03, acc. prob=0.871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.7269042843332076\n",
      "R2_test variance 0.36285350545149175\n",
      "RMSE 0.27888843035326594\n",
      "MAE 0.23471373697908796\n",
      "Performing iteration : 2\n",
      "Number of training data with variance: 28\n",
      "Number of pooling data with variance: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:21,  1.31s/it, step size=4.76e-03, acc. prob=0.945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.8399681560106896\n",
      "R2_test variance 0.6777273899614484\n",
      "RMSE 0.198345589228227\n",
      "MAE 0.16356079853184052\n",
      "Performing iteration : 3\n",
      "Number of training data with variance: 36\n",
      "Number of pooling data with variance: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:16,  1.28s/it, step size=4.05e-03, acc. prob=0.967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.8763395930574672\n",
      "R2_test variance 0.7155948445897347\n",
      "RMSE 0.18632862591502772\n",
      "MAE 0.1363743350864311\n",
      "Performing iteration : 4\n",
      "Number of training data with variance: 44\n",
      "Number of pooling data with variance: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:21,  1.31s/it, step size=3.12e-03, acc. prob=0.957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.8984341760956256\n",
      "R2_test variance 0.774817751958591\n",
      "RMSE 0.1657974795797325\n",
      "MAE 0.13213508726598644\n",
      "Performing iteration : 5\n",
      "Number of training data with variance: 52\n",
      "Number of pooling data with variance: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:19,  1.30s/it, step size=3.66e-03, acc. prob=0.958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.8969721937777837\n",
      "R2_test variance 0.7885231128672816\n",
      "RMSE 0.16067277833817833\n",
      "MAE 0.12648269168954449\n",
      "Performing iteration : 6\n",
      "Number of training data with variance: 60\n",
      "Number of pooling data with variance: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:35,  1.38s/it, step size=3.26e-03, acc. prob=0.947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.8985690659325073\n",
      "R2_test variance 0.8042111623185682\n",
      "RMSE 0.15459833525959396\n",
      "MAE 0.1279352098624478\n",
      "Performing iteration : 7\n",
      "Number of training data with variance: 68\n",
      "Number of pooling data with variance: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:38,  1.39s/it, step size=3.86e-03, acc. prob=0.885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.8895249412818225\n",
      "R2_test variance 0.791140015014119\n",
      "RMSE 0.15967556817800502\n",
      "MAE 0.12752473965449965\n",
      "Performing iteration : 8\n",
      "Number of training data with variance: 76\n",
      "Number of pooling data with variance: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:15,  1.28s/it, step size=5.92e-03, acc. prob=0.787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.8906754696959529\n",
      "R2_test variance 0.7811368305729007\n",
      "RMSE 0.16345461650372542\n",
      "MAE 0.12444410901349891\n",
      "Performing iteration : 9\n",
      "Number of training data with variance: 84\n",
      "Number of pooling data with variance: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:34,  1.37s/it, step size=2.98e-03, acc. prob=0.974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.8824515150320309\n",
      "R2_test variance 0.7735695234770201\n",
      "RMSE 0.16625636817966952\n",
      "MAE 0.13475790099490925\n",
      "Performing iteration : 10\n",
      "Number of training data with variance: 92\n",
      "Number of pooling data with variance: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:38,  1.39s/it, step size=3.02e-03, acc. prob=0.970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.8922371794388899\n",
      "R2_test variance 0.791016611093634\n",
      "RMSE 0.1597227329841045\n",
      "MAE 0.12601140737967637\n",
      "Performing iteration : 11\n",
      "Number of training data with variance: 100\n",
      "Number of pooling data with variance: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:31,  1.36s/it, step size=3.31e-03, acc. prob=0.932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.9065974084022204\n",
      "R2_test variance 0.819433340588416\n",
      "RMSE 0.1484668966345859\n",
      "MAE 0.11557288339749315\n",
      "Performing iteration : 12\n",
      "Number of training data with variance: 108\n",
      "Number of pooling data with variance: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:51,  1.46s/it, step size=2.52e-03, acc. prob=0.953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.9069714021178755\n",
      "R2_test variance 0.8155329268968359\n",
      "RMSE 0.15006184350976418\n",
      "MAE 0.11262209083108378\n",
      "Performing iteration : 13\n",
      "Number of training data with variance: 116\n",
      "Number of pooling data with variance: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:44,  1.42s/it, step size=2.43e-03, acc. prob=0.938]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCC_test variance 0.9133069143382854\n",
      "R2_test variance 0.8273152543551953\n",
      "RMSE 0.14519037822216643\n",
      "MAE 0.10009469985552619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    # random sampling\\n    if i != 0:\\n        # select 10 random data points\\n        q_points_ran = np.random.choice(np.arange(len(idx_pool_ran)), size=10)\\n        # indices of those points in idx_pool\\n        idx_pool_train_ran = idx_pool_ran[q_points_ran]\\n\\n        idx_train_ran = np.append(idx_train_ran, idx_pool_train_ran)\\n        idx_pool_ran = np.delete(idx_pool_ran, q_points_ran)\\n        X_train_ran = X[idx_train_ran]\\n        y_train_ran = y[idx_train_ran]\\n\\n    print(f\"Number of training data with random: {len(idx_train_ran)}\")\\n    print(f\"Number of training data with random: {len(idx_pool_ran)}\")\\n\\n\\n    model = BNN(hid_dim=10, n_hid_layers=3, prior_scale=1)\\n    nuts_kernel = NUTS(model, jit_compile=False)\\n    mcmc = MCMC(nuts_kernel, num_samples=50)\\n    mcmc.run(torch.Tensor(X_train_ran), torch.Tensor(y_train_ran))\\n    predictive_ran = Predictive(model=model, posterior_samples=mcmc.get_samples())\\n    preds_ran = predictive_ran(torch.Tensor(X_test))\\n    # mean of test data\\n    y_pred_ran = preds_ran[\\'obs\\'].T.detach().numpy().mean(axis=1)\\n    y_std_ran = preds_ran[\\'obs\\'].T.detach().numpy().std(axis=1)\\n    y_pred_test_ran = y_pred_ran\\n\\n    print(\\'PCC_test random\\', pearsonr(np.squeeze(y_test), np.squeeze(y_pred_test_ran))[0])\\n    print(\\'R2_test random\\', r2_score(np.squeeze(y_test), np.squeeze(y_pred_test_ran)))\\n    pcc_random.append(pearsonr(np.squeeze(y_test), np.squeeze(y_pred_test_ran))[0])\\n    r2_random.append(r2_score(np.squeeze(y_test), np.squeeze(y_pred_test_ran)))\\n\\n    num_iteration.append(i)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter = 14\n",
    "test_list = []\n",
    "\n",
    "for i in range(n_iter):\n",
    "    print(f\"Performing iteration : {i}\")\n",
    "\n",
    "    if i != 0:\n",
    "        # find 10 data points with the highest variance\n",
    "        \n",
    "        q_points_var = np.argpartition(y_pred_unc_pool_var, -8)[-8:]\n",
    "        # indices of those points in idx_pool\n",
    "        idx_pool_train_var = idx_pool_var[q_points_var]\n",
    "\n",
    "        idx_train_var = np.append(idx_train_var, idx_pool_train_var)\n",
    "        idx_pool_var = np.delete(idx_pool_var, q_points_var)\n",
    "        \n",
    "        X_train_var = X[idx_train_var]\n",
    "        y_train_var = y[idx_train_var]\n",
    "       \n",
    "\n",
    "    print(f\"Number of training data with variance: {len(idx_train_var)}\")\n",
    "    print(f\"Number of pooling data with variance: {len(idx_pool_var)}\")\n",
    "    \n",
    "    num_training_data.append(len(idx_train_var))\n",
    "    \n",
    "    model = BNN(hid_dim=10, n_hid_layers=3, prior_scale=1)\n",
    "    nuts_kernel = NUTS(model, jit_compile=False)\n",
    "    mcmc = MCMC(nuts_kernel, num_samples=100)\n",
    "    mcmc.run(torch.Tensor(X_train_var), torch.Tensor(y_train_var))\n",
    "    predictive_var = Predictive(model=model, posterior_samples=mcmc.get_samples())\n",
    "    preds_var = predictive_var(torch.Tensor(X_test))\n",
    "\n",
    "    # mean and standard deviation of the test dataset\n",
    "    y_pred_test_var = preds_var['obs'].T.detach().numpy().mean(axis=1)\n",
    "    y_std_test_var = preds_var['obs'].T.detach().numpy().std(axis=1)\n",
    "\n",
    "    preds_pool_var = predictive_var(torch.Tensor(X[idx_pool_var]))\n",
    "    y_pred_unc_pool_var = preds_pool_var['obs'].T.detach().numpy().std(axis=1)\n",
    "\n",
    "    print('PCC_test variance', pearsonr(np.squeeze(y_test), np.squeeze(y_pred_test_var))[0])\n",
    "    print('R2_test variance', r2_score(np.squeeze(y_test), np.squeeze(y_pred_test_var)))\n",
    "    print('RMSE', np.sqrt(mean_squared_error(y_test, y_pred_test_var)))\n",
    "    print('MAE', np.mean(abs(y_test - y_pred_test_var)))\n",
    "\n",
    "    pcc_variance.append(pearsonr(np.squeeze(y_test), np.squeeze(y_pred_test_var))[0])\n",
    "    r2_variance.append(r2_score(np.squeeze(y_test), np.squeeze(y_pred_test_var)))\n",
    "    rmse_variance.append(np.sqrt(mean_squared_error(y_test, y_pred_test_var)))\n",
    "    mae_variance.append(np.mean(abs(y_test - y_pred_test_var)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('AL_MCMC_Ni.pkl', 'wb') as f:\n",
    "\n",
    "    pickle.dump({'train_numbs':num_training_data, 'pcc':pcc_variance,'r2':r2_variance, 'rsme': rmse_variance, 'mae': mae_variance}, f)\n",
    "    f.close()\n",
    "\n",
    "pkl_file = open('AL_MCMC_Ni.pkl', 'rb')  \n",
    "test_ALGPR = pickle.load(pkl_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
