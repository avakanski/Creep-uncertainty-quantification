{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from scipy.stats import pearsonr\n",
    "import torchbnn as bnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ni</th>\n",
       "      <th>Al</th>\n",
       "      <th>Co</th>\n",
       "      <th>Cr</th>\n",
       "      <th>Mo</th>\n",
       "      <th>Re</th>\n",
       "      <th>Ru</th>\n",
       "      <th>Ta</th>\n",
       "      <th>W</th>\n",
       "      <th>Ti</th>\n",
       "      <th>Nb</th>\n",
       "      <th>T</th>\n",
       "      <th>log_stress</th>\n",
       "      <th>log_creep_life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.80</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>950</td>\n",
       "      <td>2.267172</td>\n",
       "      <td>3.276554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.30</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>2.136721</td>\n",
       "      <td>3.026370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.80</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2.389166</td>\n",
       "      <td>3.009026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.30</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>2.389166</td>\n",
       "      <td>2.969556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.68</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>2.079181</td>\n",
       "      <td>2.957607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>61.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1100</td>\n",
       "      <td>2.322219</td>\n",
       "      <td>1.155336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>61.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1070</td>\n",
       "      <td>2.447158</td>\n",
       "      <td>1.089905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>61.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1100</td>\n",
       "      <td>2.352183</td>\n",
       "      <td>0.991226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>61.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1100</td>\n",
       "      <td>2.342423</td>\n",
       "      <td>0.968483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>61.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1070</td>\n",
       "      <td>2.434569</td>\n",
       "      <td>0.919078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ni   Al   Co   Cr   Mo   Re   Ru   Ta    W   Ti   Nb     T  \\\n",
       "0    62.80  5.6  9.0  6.5  0.6  3.0  0.0  6.5  6.0  0.0  0.0   950   \n",
       "1    59.30  5.8  5.8  2.9  3.9  4.9  6.0  5.6  5.8  0.0  0.0  1100   \n",
       "2    59.80  5.6  5.6  4.6  2.4  6.4  5.0  5.6  5.0  0.0  0.0  1000   \n",
       "3    59.30  5.8  5.8  2.9  3.9  4.9  6.0  5.6  5.8  0.0  0.0  1000   \n",
       "4    61.68  6.0  9.0  3.5  1.5  4.0  0.0  8.0  6.0  0.2  0.0  1100   \n",
       "..     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
       "148  61.00  5.6  9.0  4.3  2.0  2.0  0.0  7.5  8.0  0.0  0.5  1100   \n",
       "149  61.00  5.6  9.0  4.3  2.0  2.0  0.0  7.5  8.0  0.0  0.5  1070   \n",
       "150  61.00  5.6  9.0  4.3  2.0  2.0  0.0  7.5  8.0  0.0  0.5  1100   \n",
       "151  61.00  5.6  9.0  4.3  2.0  2.0  0.0  7.5  8.0  0.0  0.5  1100   \n",
       "152  61.00  5.6  9.0  4.3  2.0  2.0  0.0  7.5  8.0  0.0  0.5  1070   \n",
       "\n",
       "     log_stress  log_creep_life  \n",
       "0      2.267172        3.276554  \n",
       "1      2.136721        3.026370  \n",
       "2      2.389166        3.009026  \n",
       "3      2.389166        2.969556  \n",
       "4      2.079181        2.957607  \n",
       "..          ...             ...  \n",
       "148    2.322219        1.155336  \n",
       "149    2.447158        1.089905  \n",
       "150    2.352183        0.991226  \n",
       "151    2.342423        0.968483  \n",
       "152    2.434569        0.919078  \n",
       "\n",
       "[153 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import creep data\n",
    "creep_df = pd.read_csv('Ni_superalloys_dataset.csv')\n",
    "creep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_state = 123\n",
    "test_size = 0.2\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(np.array(creep_df.iloc[:, 0:13]), np.array(creep_df.iloc[:,13]), shuffle=True, test_size=test_size, random_state=rm_state)\n",
    "\n",
    "idx = np.arange(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.1\n",
    "\n",
    "X_train, _, y_train, _, idx_train, idx_pool = train_test_split(X, y, idx, train_size=train_ratio, shuffle=True, random_state=rm_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(dtype=np.float32)\n",
    "X_test =X_test.astype(np.float32)\n",
    "X_train =X_train.astype(np.float32)\n",
    "\n",
    "y = y.astype(dtype=np.float32)\n",
    "y_test = y_test.astype(dtype=np.float32)\n",
    "y_train = y_train.astype(dtype=np.float32)\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y = torch.from_numpy(y)\n",
    "\n",
    "y_train = torch.unsqueeze(y_train, dim=1)\n",
    "y_test = torch.unsqueeze(y_test, dim=1)\n",
    "y = torch.unsqueeze(y, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing iteration : 0\n",
      "Number of training data with variance: 12\n",
      "Number of pooling data with variance: 110\n",
      "PCC_test_score 0.1786703148586526\n",
      "R2_test_score -1.879705908893786\n",
      "RMSE 0.59290475\n",
      "MAE 0.38907248\n",
      "Performing iteration : 1\n",
      "\n",
      "Number of training data with variance: 20\n",
      "Number of pooling data with variance: 102\n",
      "PCC_test_score 0.14358931785906826\n",
      "R2_test_score -1.5303146167145307\n",
      "RMSE 0.5557739\n",
      "MAE 0.3662951\n",
      "Performing iteration : 2\n",
      "\n",
      "Number of training data with variance: 28\n",
      "Number of pooling data with variance: 94\n",
      "PCC_test_score 0.486561203007658\n",
      "R2_test_score 0.030241312457769176\n",
      "RMSE 0.34406677\n",
      "MAE 0.25744224\n",
      "Performing iteration : 3\n",
      "\n",
      "Number of training data with variance: 36\n",
      "Number of pooling data with variance: 86\n",
      "PCC_test_score 0.5586161883007214\n",
      "R2_test_score 0.26012269652014464\n",
      "RMSE 0.300532\n",
      "MAE 0.23046476\n",
      "Performing iteration : 4\n",
      "\n",
      "Number of training data with variance: 44\n",
      "Number of pooling data with variance: 78\n",
      "PCC_test_score 0.68551390222266\n",
      "R2_test_score 0.44809924137878643\n",
      "RMSE 0.25956213\n",
      "MAE 0.20415603\n",
      "Performing iteration : 5\n",
      "\n",
      "Number of training data with variance: 52\n",
      "Number of pooling data with variance: 70\n",
      "PCC_test_score 0.6895282778046372\n",
      "R2_test_score 0.4359387120298094\n",
      "RMSE 0.26240617\n",
      "MAE 0.21093024\n",
      "Performing iteration : 6\n",
      "\n",
      "Number of training data with variance: 60\n",
      "Number of pooling data with variance: 62\n",
      "PCC_test_score 0.7821732168118828\n",
      "R2_test_score 0.6094096595509289\n",
      "RMSE 0.21835928\n",
      "MAE 0.1759664\n",
      "Performing iteration : 7\n",
      "\n",
      "Number of training data with variance: 68\n",
      "Number of pooling data with variance: 54\n",
      "PCC_test_score 0.8536000770921742\n",
      "R2_test_score 0.7171779994700516\n",
      "RMSE 0.18580931\n",
      "MAE 0.15347551\n",
      "Performing iteration : 8\n",
      "\n",
      "Number of training data with variance: 76\n",
      "Number of pooling data with variance: 46\n",
      "PCC_test_score 0.8687312905544913\n",
      "R2_test_score 0.7499093668480228\n",
      "RMSE 0.17472683\n",
      "MAE 0.14029916\n",
      "Performing iteration : 9\n",
      "\n",
      "Number of training data with variance: 84\n",
      "Number of pooling data with variance: 38\n",
      "PCC_test_score 0.8810186344988558\n",
      "R2_test_score 0.773820266800348\n",
      "RMSE 0.1661643\n",
      "MAE 0.1327882\n",
      "Performing iteration : 10\n",
      "\n",
      "Number of training data with variance: 92\n",
      "Number of pooling data with variance: 30\n",
      "PCC_test_score 0.8903809451463275\n",
      "R2_test_score 0.7894338787452035\n",
      "RMSE 0.16032644\n",
      "MAE 0.12705159\n",
      "Performing iteration : 11\n",
      "\n",
      "Number of training data with variance: 100\n",
      "Number of pooling data with variance: 22\n",
      "PCC_test_score 0.8980194930036777\n",
      "R2_test_score 0.7996312098827804\n",
      "RMSE 0.1563961\n",
      "MAE 0.1276685\n",
      "Performing iteration : 12\n",
      "\n",
      "Number of training data with variance: 108\n",
      "Number of pooling data with variance: 14\n",
      "PCC_test_score 0.9005848219433272\n",
      "R2_test_score 0.8011578731496782\n",
      "RMSE 0.15579915\n",
      "MAE 0.13146608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    # random sampling\\n    if i != 0:\\n        # select 10 random data points\\n        q_points_ran = np.random.choice(np.arange(len(idx_pool_ran)), size=10)\\n        # indices of those points in idx_pool\\n        idx_pool_train_ran = idx_pool_ran[q_points_ran]\\n\\n        idx_train_ran = np.append(idx_train_ran, idx_pool_train_ran)\\n        idx_pool_ran = np.delete(idx_pool_ran, q_points_ran)\\n        X_train_ran = X[idx_train_ran]\\n        y_train_ran = y[idx_train_ran]\\n\\n    print(f\"Number of training data with random: {len(idx_train_ran)}\")\\n    print(f\"Number of pooling data with random: {len(idx_pool_ran)}\")\\n\\n    for step in range(3000):\\n\\n\\n        y_pred_ran = model(X_train_ran)\\n        mse = mse_loss(y_pred_ran, y_train_ran)\\n        kl = kl_loss(model)\\n        cost = mse + kl_weight*kl\\n\\n        optimizer.zero_grad()\\n        cost.backward()\\n        optimizer.step()\\n\\n    if step % 1000==0:\\n        print(\\'MSE : %2.2f, KL : %2.2f\\' % (mse.item(), kl.item()))\\n\\n    n_samples = 1000\\n\\n    # compute predictions\\n    y_preds_ran = [model(X_test).clone().detach().numpy() for _ in range(n_samples)]\\n    y_preds_ran = np.array(y_preds_ran)\\n    # mean and standard deviation\\n    y_pred_test_ran = np.mean(y_preds_ran, axis=0)\\n    y_pred_unc_test_ran = np.std(y_preds_ran, axis=0)\\n    # y_test = y_test.detach().numpy()\\n\\n\\n    # get the idx pool ran\\n    y_preds_pool_ran = [model(X[idx_pool_ran]).clone().detach().numpy() for _ in range(n_samples)]\\n    y_preds_pool_ran = np.array(y_preds_pool_ran)\\n    y_pred_unc_pool_ran = np.squeeze(np.std(y_preds_pool_ran, axis=0))\\n\\n    print(\\'PCC_test\\', pearsonr(np.squeeze(y_test.numpy()), np.squeeze(y_pred_test_ran))[0])\\n    print(\\'R2_test\\', r2_score(np.squeeze(y_test.numpy()), np.squeeze(y_pred_test_ran)))\\n    pcc_random.append(pearsonr(np.squeeze(y_test.numpy()), np.squeeze(y_pred_test_ran))[0])\\n    r2_random.append(r2_score(np.squeeze(y_test.numpy()), np.squeeze(y_pred_test_ran)))\\n\\n    num_iteration.append(i)\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter = 13\n",
    "pcc_variance = []\n",
    "r2_variance = []\n",
    "rmse_variance = []\n",
    "mae_variance = []\n",
    "pcc_random = []\n",
    "r2_random = []\n",
    "num_training_data = []\n",
    "\n",
    "X_train_var = X_train\n",
    "X_train_ran = X_train\n",
    "y_train_var = y_train\n",
    "y_train_ran = y_train\n",
    "idx_pool_var = idx_pool\n",
    "idx_pool_ran = idx_pool\n",
    "idx_train_var = idx_train\n",
    "idx_train_ran = idx_train\n",
    "\n",
    "#build the model \n",
    "model = nn.Sequential(\n",
    "        bnn.BayesLinear(prior_mu=0, prior_sigma=0.06, in_features=13, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        bnn.BayesLinear(prior_mu=0, prior_sigma=0.06, in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        bnn.BayesLinear(prior_mu=0, prior_sigma=0.06, in_features=100, out_features=100),\n",
    "        nn.ReLU(),\n",
    "        bnn.BayesLinear(prior_mu=0, prior_sigma=0.06, in_features=100, out_features=1),\n",
    ")\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
    "kl_weight = 0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, nesterov=True, momentum=0.95)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    print(f\"Performing iteration : {i}\")\n",
    "\n",
    "    if i != 0:\n",
    "        # find 10 data points with the highest variance\n",
    "        print()\n",
    "   \n",
    "        q_points_var = np.argpartition(y_pred_unc_pool_var, -8)[-8:]\n",
    "        # indices of those points in idx_pool\n",
    "        idx_pool_train_var = idx_pool_var[q_points_var]\n",
    "\n",
    "        idx_train_var = np.append(idx_train_var, idx_pool_train_var)\n",
    "        idx_pool_var = np.delete(idx_pool_var, q_points_var)\n",
    "        X_train_var = X[idx_train_var]\n",
    "        y_train_var = y[idx_train_var]\n",
    "\n",
    "    print(f\"Number of training data with variance: {len(idx_train_var)}\")\n",
    "    print(f\"Number of pooling data with variance: {len(idx_pool_var)}\")\n",
    "    \n",
    "    num_training_data.append(len(idx_train_var))\n",
    "\n",
    "    for step in range(3000):\n",
    "        y_pred_var = model(X_train_var)\n",
    "        \n",
    "        mse = mse_loss(y_pred_var, y_train_var)\n",
    "        kl = kl_loss(model)\n",
    "        cost = mse + kl_weight*kl\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if step % 1000==0:\n",
    "        print('MSE : %2.2f, KL : %2.2f' % (mse.item(), kl.item()))\n",
    "\n",
    "    n_samples = 1000\n",
    "\n",
    "    # compute predictions\n",
    "    y_preds_var = [model(X_test).clone().detach().numpy() for _ in range(n_samples)]\n",
    "    y_preds_var = np.array(y_preds_var)\n",
    "    # mean and standard deviation\n",
    "    y_pred_test_var = np.mean(y_preds_var, axis=0)\n",
    "    y_pred_unc_test_var = np.std(y_preds_var, axis=0)\n",
    "    # y_test = y_test.detach().numpy()\n",
    "\n",
    "\n",
    "    # get the idx pool var\n",
    "    y_preds_pool_var = [model(X[idx_pool_var]).clone().detach().numpy() for _ in range(n_samples)]\n",
    "    y_preds_pool_var = np.array(y_preds_pool_var)\n",
    "    y_pred_unc_pool_var = np.squeeze(np.std(y_preds_pool_var, axis=0))\n",
    "\n",
    "    print('PCC_test_score', pearsonr(np.squeeze(y_test.numpy()), np.squeeze(y_pred_test_var))[0])\n",
    "    print('R2_test_score', r2_score(np.squeeze(y_test.numpy()), np.squeeze(y_pred_test_var)))\n",
    "    print('RMSE', np.sqrt(mean_squared_error(np.squeeze(y_test.numpy()), np.squeeze(y_pred_test_var))))\n",
    "    print('MAE', np.mean(abs(np.squeeze(y_test.numpy()) - np.squeeze(y_pred_test_var))))\n",
    "\n",
    "    pcc_variance.append(pearsonr(np.squeeze(y_test.numpy()), np.squeeze(y_pred_test_var))[0])\n",
    "    r2_variance.append(r2_score(np.squeeze(y_test.numpy()), np.squeeze(y_pred_test_var)))\n",
    "    rmse_variance.append(np.sqrt(mean_squared_error(np.squeeze(y_test.numpy()), np.squeeze(y_pred_test_var))))\n",
    "    mae_variance.append(np.mean(abs(np.squeeze(y_test.numpy())- np.squeeze(y_pred_test_var))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AL_BNN_VarInf_Ni.pkl', 'wb') as f:\n",
    "    pickle.dump({'train_numbs':num_training_data, 'pcc':pcc_variance,'r2':r2_variance, 'rsme': rmse_variance, 'mae': mae_variance}, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = open('AL_BNN_VarInf_Ni.pkl', 'rb')  \n",
    "test = pickle.load(pkl_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
